trainN <- trainN [ ,kk$k0]
trainN       <- subset(trainN, select = vasrthatareidenticalinclass)
testN        <- subset(testN , select = vasrthatareidenticalinclass)
names(testN)
# qitamos los factores
trainN <- trainN[,-c(3:4)]
testN <- testN[,-c(3:4)]
# df     <- trainN
# cosa   <- df[,-sapply(df,is.factor)]
# trainN <- cosa
#
# df     <- testN
# cosa   <- df[,-sapply(df,is.factor)]
# testN <- cosa
# # comprobamos q ya son iguales
# k1 <-sapply(trainN, class)
# k2 <-sapply(testN, class)
# kk <-data.frame(k1,k2, k0=NA, stringsAsFactors = FALSE)
#
# obsoleto
# k1<-as.data.frame(names(trainN))
# names(k1)<-"vars1"
#
# k2<-as.data.frame(names(testN))
# names(k2)<-"vars2"
#  problema de las class de test
# cbind(k1, k2)
# names(trainN[,sapply(trainN,is.factor)])
# names(testN[,sapply(testN,is.factor)])
#
# names(trainN[,sapply(trainN,is.numeric)])
# names(testN[,sapply(testN,is.numeric)])
# Chunk 10
set.seed(pi)
casostest1  <- createDataPartition(myclasse, p=0.6, list = FALSE)
str(casostest1)
train1      <- trainN [casostest1,]  # trainning data set
train2      <- trainN [-casostest1,] # proving data set
# Chunk 11
# library( "randomForest" )
# RandomForest does not work with factosr that have a lot of levels
# so we create a function to select only those fcator variables
# with less than a certain numeber (nl) of levels
mynl <- 9
flevels <- function(v, nl = mynl ){
if (nlevels(v)< nl) return (TRUE)
else return(FALSE)
}
system.time(
rfo2 <- randomForest( myclasse[casostest1] ~. , data = train1
# rfo2 <- randomForest( myclasse[casostest1] ~. , data = train1[,sapply(train1, flevels)]
# , mtry = 7  # el default es raiz(p)/3, donde p es el num de vars
# , subset = train
, importance=TRUE)
)
# varsinmodel <- names( train1[,sapply(train1, flevels)] )
# Chunk 12
pander(importance(rfo2))
# Chunk 13
varImpPlot(rfo2)
# Chunk 14
train2_prediction <- predict(rfo2, newdata=train2)
kk<-confusionMatrix(train2_prediction, myclasse[-casostest1])
# str(kk)
pander(kk$overall[1:2], caption="overall.")
pander(kk$table, caption="Confusion table.")
pander(t(kk$byClass), caption="model parameters by class.")
# confusionMatrix(train2_prediction, myclasse[-casostest1])$overall['Accuracy']
testN2_prediction <- predict(rfo2, newdata=testN)
testN2_prediction
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE, echo=T, results="asis", cahe=TRUE)
options(scipen = 1, digits = 3)  # set default digits
library(pander)
library(caret)
library(devtools)
# install_github("ujjwalkarn/xda")
library(xda)
library( "randomForest" )
# library(xtable)
# library("lattice")
# Chunk 2
# download data from the source url
filepath     <- "XXXXX"
filepath     <- "pml-training.csv"
train <- read.table(filepath,  sep="," , header=T, dec=".")
filepath     <- "XXX"
filepath     <- "pml-testing.csv"
test <- read.table(filepath,  sep="," , header=T, dec=".")
# Chunk 3
n         <- nrow(train)
f.numofna <- function (vector){
return( sum(is.na (vector)))
}
x       <- as.vector(apply(train, 2, f.numofna)/n)
pander(table(x), caption = "Number of variables with a percentaje of missiing values: `0%` or `97%`")
varsnona <- (x<0.8)
n1    <- length(names(train))
train <- train[,varsnona]
test  <- test[,varsnona]
# kk<-lapply(train,data.class)
# pander(kk)
n2 <- length(names(train))
# Chunk 4
tt<-table(train$classe)
pander::pander(tt,caption="absolute frecuency of classes of variebl classe")
tt<- prop.table(tt)*100
pander::pander(tt,caption="percentage table")
# Chunk 5
pander(numSummary(train)[,-c(7:17)], caption="Preliminary descriptives of numerical variables in the trainning dataset.")
# Chunk 6
pander(charSummary(train), caption="Preliminary descriptives of non numerical variables in the trainning dataset.")
# Chunk 7
procValues <- preProcess(train, method = c("center", "scale"))
trainN     <- predict(procValues, train)
testN      <- predict(procValues, test)
# Chunk 8: ctosfinales
trainN <- trainN[,-c(1:2)] # delete the id var and username
testN <- testN[,-c(1:2)]
myclasse     <- trainN$classe  # classification/outcome variable
trainN       <- subset(trainN, select = -c(classe))
testN        <- subset(testN , select = -c(problem_id))
# Chunk 9: probClases
# problema con las classes de las variables aml! 20160621
k1 <-sapply(trainN, class)
k2 <-sapply(testN, class)
kk <-data.frame(k1,k2, k0=NA, stringsAsFactors = FALSE)
# str(kk)
# head(kk)
for (i in 1: nrow(kk)){
if (kk$k1[i]==kk$k2[i]) { kk$k0[i] <- TRUE }
else{ kk$k0[i]<- FALSE}
}
length(rownames(kk))
# rownames(kk)[kk$k0]
# there are variaboles thar are not of the same type (class) in both datasets
pander(kk[kk$k0==FALSE,1:2], caption="Variables in datasets thar are not of the same data class.")
vasrthatareidenticalinclass <- rownames(kk)[kk$k0]  # in boyh dataframes
trainN <- trainN [ ,kk$k0]
trainN       <- subset(trainN, select = vasrthatareidenticalinclass)
testN        <- subset(testN , select = vasrthatareidenticalinclass)
names(sapply(trainN,is.factor))
names(trainN[,sapply(trainN,is.factor)])
names(testN[,sapply(testN,is.factor)])
trainN <- trainN[,-sapply(trainN,is.factor)]
names(trainN[,sapply(trainN,is.factor)])
trainN <- trainN[,-sapply(trainN,is.factor)]
names(trainN[,sapply(trainN,is.factor)])
View(trainN)
sapply(trainN,is.factor)
trainN[,sapply(trainN,is.factor)]
trainN <- trainN[,-c(sapply(trainN,is.factor))]
View(trainN)
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE, echo=T, results="asis", cahe=TRUE)
options(scipen = 1, digits = 3)  # set default digits
library(pander)
library(caret)
library(devtools)
# install_github("ujjwalkarn/xda")
library(xda)
library( "randomForest" )
# library(xtable)
# library("lattice")
# Chunk 2
# download data from the source url
filepath     <- "XXXXX"
filepath     <- "pml-training.csv"
train <- read.table(filepath,  sep="," , header=T, dec=".")
filepath     <- "XXX"
filepath     <- "pml-testing.csv"
test <- read.table(filepath,  sep="," , header=T, dec=".")
# Chunk 3
n         <- nrow(train)
f.numofna <- function (vector){
return( sum(is.na (vector)))
}
x       <- as.vector(apply(train, 2, f.numofna)/n)
pander(table(x), caption = "Number of variables with a percentaje of missiing values: `0%` or `97%`")
varsnona <- (x<0.8)
n1    <- length(names(train))
train <- train[,varsnona]
test  <- test[,varsnona]
# kk<-lapply(train,data.class)
# pander(kk)
n2 <- length(names(train))
# Chunk 4
tt<-table(train$classe)
pander::pander(tt,caption="absolute frecuency of classes of variebl classe")
tt<- prop.table(tt)*100
pander::pander(tt,caption="percentage table")
# Chunk 5
pander(numSummary(train)[,-c(7:17)], caption="Preliminary descriptives of numerical variables in the trainning dataset.")
# Chunk 6
pander(charSummary(train), caption="Preliminary descriptives of non numerical variables in the trainning dataset.")
# Chunk 7
procValues <- preProcess(train, method = c("center", "scale"))
trainN     <- predict(procValues, train)
testN      <- predict(procValues, test)
# Chunk 8: ctosfinales
trainN <- trainN[,-c(1:2)] # delete the id var and username
testN <- testN[,-c(1:2)]
myclasse     <- trainN$classe  # classification/outcome variable
trainN       <- subset(trainN, select = -c(classe))
testN        <- subset(testN , select = -c(problem_id))
# Chunk 9: probClases
# problema con las classes de las variables aml! 20160621
k1 <-sapply(trainN, class)
k2 <-sapply(testN, class)
kk <-data.frame(k1,k2, k0=NA, stringsAsFactors = FALSE)
# str(kk)
# head(kk)
for (i in 1: nrow(kk)){
if (kk$k1[i]==kk$k2[i]) { kk$k0[i] <- TRUE }
else{ kk$k0[i]<- FALSE}
}
length(rownames(kk))
# rownames(kk)[kk$k0]
# there are variaboles thar are not of the same type (class) in both datasets
pander(kk[kk$k0==FALSE,1:2], caption="Variables in datasets thar are not of the same data class.")
vasrthatareidenticalinclass <- rownames(kk)[kk$k0]  # in boyh dataframes
trainN <- trainN [ ,kk$k0]
trainN       <- subset(trainN, select = vasrthatareidenticalinclass)
testN        <- subset(testN , select = vasrthatareidenticalinclass)
names(trainN[,sapply(trainN,is.factor)])
names(testN[,sapply(testN,is.factor)])
trainN <- trainN[,-c(sapply(trainN,is.factor))]
testN <- testN[,-c(sapply(testN,is.factor))]
set.seed(pi)
casostest1  <- createDataPartition(myclasse, p=0.6, list = FALSE)
str(casostest1)
train1      <- trainN [casostest1,]  # trainning data set
train2      <- trainN [-casostest1,] # proving data set
rfo2 <- randomForest( myclasse[casostest1] ~. , data = train1
)
rfo2
rfo2 <- randomForest( myclasse[casostest1] ~. , data = train1
# rfo2 <- randomForest( myclasse[casostest1] ~. , data = train1[,sapply(train1, flevels)]
# , mtry = 7  # el default es raiz(p)/3, donde p es el num de vars
# , subset = train
, importance=TRUE)
)
rfo2
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE, echo=T, results="asis", cahe=TRUE)
options(scipen = 1, digits = 3)  # set default digits
library(pander)
library(caret)
library(devtools)
# install_github("ujjwalkarn/xda")
library(xda)
library( "randomForest" )
# library(xtable)
# library("lattice")
# Chunk 2
# download data from the source url
filepath     <- "XXXXX"
filepath     <- "pml-training.csv"
train <- read.table(filepath,  sep="," , header=T, dec=".")
filepath     <- "XXX"
filepath     <- "pml-testing.csv"
test <- read.table(filepath,  sep="," , header=T, dec=".")
# Chunk 3
n         <- nrow(train)
f.numofna <- function (vector){
return( sum(is.na (vector)))
}
x       <- as.vector(apply(train, 2, f.numofna)/n)
pander(table(x), caption = "Number of variables with a percentaje of missiing values: `0%` or `97%`")
varsnona <- (x<0.8)
n1    <- length(names(train))
train <- train[,varsnona]
test  <- test[,varsnona]
# kk<-lapply(train,data.class)
# pander(kk)
n2 <- length(names(train))
# Chunk 4
tt<-table(train$classe)
pander::pander(tt,caption="absolute frecuency of classes of variebl classe")
tt<- prop.table(tt)*100
pander::pander(tt,caption="percentage table")
# Chunk 5
pander(numSummary(train)[,-c(7:17)], caption="Preliminary descriptives of numerical variables in the trainning dataset.")
# Chunk 6
pander(charSummary(train), caption="Preliminary descriptives of non numerical variables in the trainning dataset.")
# Chunk 7
procValues <- preProcess(train, method = c("center", "scale"))
trainN     <- predict(procValues, train)
testN      <- predict(procValues, test)
# Chunk 8: ctosfinales
trainN <- trainN[,-c(1:2)] # delete the id var and username
testN <- testN[,-c(1:2)]
myclasse     <- trainN$classe  # classification/outcome variable
trainN       <- subset(trainN, select = -c(classe))
testN        <- subset(testN , select = -c(problem_id))
# Chunk 9: probClases
# problema con las classes de las variables aml! 20160621
k1 <-sapply(trainN, class)
k2 <-sapply(testN, class)
kk <-data.frame(k1,k2, k0=NA, stringsAsFactors = FALSE)
# str(kk)
# head(kk)
for (i in 1: nrow(kk)){
if (kk$k1[i]==kk$k2[i]) { kk$k0[i] <- TRUE }
else{ kk$k0[i]<- FALSE}
}
length(rownames(kk))
# rownames(kk)[kk$k0]
# there are variaboles thar are not of the same type (class) in both datasets
pander(kk[kk$k0==FALSE,1:2], caption="Variables in datasets thar are not of the same data class.")
vasrthatareidenticalinclass <- rownames(kk)[kk$k0]  # in boyh dataframes
trainN <- trainN [ ,kk$k0]
trainN       <- subset(trainN, select = vasrthatareidenticalinclass)
testN        <- subset(testN , select = vasrthatareidenticalinclass)
# Chunk 10
# qitamos los factores
names(trainN[,sapply(trainN,is.factor)])
names(testN[,sapply(testN,is.factor)])
trainN <- trainN[,-c(sapply(trainN,is.factor))]
testN <- testN[,-c(sapply(testN,is.factor))]
# trainN <- trainN[,-c(3:4)]
# testN  <- testN[ ,-c(3:4)]
# Chunk 11
# df     <- trainN
# cosa   <- df[,-sapply(df,is.factor)]
# trainN <- cosa
#
# df     <- testN
# cosa   <- df[,-sapply(df,is.factor)]
# testN <- cosa
# # comprobamos q ya son iguales
# k1 <-sapply(trainN, class)
# k2 <-sapply(testN, class)
# kk <-data.frame(k1,k2, k0=NA, stringsAsFactors = FALSE)
#
# obsoleto
# k1<-as.data.frame(names(trainN))
# names(k1)<-"vars1"
#
# k2<-as.data.frame(names(testN))
# names(k2)<-"vars2"
#  problema de las class de test
# cbind(k1, k2)
# names(trainN[,sapply(trainN,is.factor)])
# names(testN[,sapply(testN,is.factor)])
#
# names(trainN[,sapply(trainN,is.numeric)])
# names(testN[,sapply(testN,is.numeric)])
# Chunk 12
set.seed(pi)
casostest1  <- createDataPartition(myclasse, p=0.6, list = FALSE)
str(casostest1)
train1      <- trainN [casostest1,]  # trainning data set
train2      <- trainN [-casostest1,] # proving data set
system.time(
rfo2 <- randomForest( myclasse[casostest1] ~. , data = train1
# rfo2 <- randomForest( myclasse[casostest1] ~. , data = train1[,sapply(train1, flevels)]
# , mtry = 7  # el default es raiz(p)/3, donde p es el num de vars
# , subset = train
, importance=TRUE)
)
train2_prediction <- predict(rfo2, newdata=train2)
train2_prediction
testN2_prediction <- predict(rfo2, newdata=testN)
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE, echo=T, results="asis", cahe=TRUE)
options(scipen = 1, digits = 3)  # set default digits
library(pander)
library(caret)
library(devtools)
# install_github("ujjwalkarn/xda")
library(xda)
library( "randomForest" )
# library(xtable)
# library("lattice")
# Chunk 2
# download data from the source url
filepath     <- "XXXXX"
filepath     <- "pml-training.csv"
train <- read.table(filepath,  sep="," , header=T, dec=".")
filepath     <- "XXX"
filepath     <- "pml-testing.csv"
test <- read.table(filepath,  sep="," , header=T, dec=".")
# Chunk 3
n         <- nrow(train)
f.numofna <- function (vector){
return( sum(is.na (vector)))
}
x       <- as.vector(apply(train, 2, f.numofna)/n)
pander(table(x), caption = "Number of variables with a percentaje of missiing values: `0%` or `97%`")
varsnona <- (x<0.8)
n1    <- length(names(train))
train <- train[,varsnona]
test  <- test[,varsnona]
# kk<-lapply(train,data.class)
# pander(kk)
n2 <- length(names(train))
# Chunk 4
tt<-table(train$classe)
pander::pander(tt,caption="absolute frecuency of classes of variebl classe")
tt<- prop.table(tt)*100
pander::pander(tt,caption="percentage table")
# Chunk 5
pander(numSummary(train)[,-c(7:17)], caption="Preliminary descriptives of numerical variables in the trainning dataset.")
# Chunk 6
pander(charSummary(train), caption="Preliminary descriptives of non numerical variables in the trainning dataset.")
# Chunk 7
procValues <- preProcess(train, method = c("center", "scale"))
trainN     <- predict(procValues, train)
testN      <- predict(procValues, test)
# Chunk 8: ctosfinales
trainN <- trainN[,-c(1:2)] # delete the id var and username
testN <- testN[,-c(1:2)]
myclasse     <- trainN$classe  # classification/outcome variable
trainN       <- subset(trainN, select = -c(classe))
testN        <- subset(testN , select = -c(problem_id))
# Chunk 9: probClases
# problema con las classes de las variables aml! 20160621
k1 <-sapply(trainN, class)
k2 <-sapply(testN, class)
kk <-data.frame(k1,k2, k0=NA, stringsAsFactors = FALSE)
# str(kk)
# head(kk)
for (i in 1: nrow(kk)){
if (kk$k1[i]==kk$k2[i]) { kk$k0[i] <- TRUE }
else{ kk$k0[i]<- FALSE}
}
length(rownames(kk))
# rownames(kk)[kk$k0]
# there are variaboles thar are not of the same type (class) in both datasets
pander(kk[kk$k0==FALSE,1:2], caption="Variables in datasets thar are not of the same data class.")
vasrthatareidenticalinclass <- rownames(kk)[kk$k0]  # in boyh dataframes
trainN <- trainN [ ,kk$k0]
trainN       <- subset(trainN, select = vasrthatareidenticalinclass)
testN        <- subset(testN , select = vasrthatareidenticalinclass)
# Chunk 10
# qitamos los factores
names(trainN[,sapply(trainN,is.factor)])
names(testN[,sapply(testN,is.factor)])
# trainN <- trainN[,-c(sapply(trainN,is.factor))]
# testN <- testN[,-c(sapply(testN,is.factor))]
trainN <- trainN[,-c(3:4)]
testN  <- testN[ ,-c(3:4)]
# Chunk 11
# df     <- trainN
# cosa   <- df[,-sapply(df,is.factor)]
# trainN <- cosa
#
# df     <- testN
# cosa   <- df[,-sapply(df,is.factor)]
# testN <- cosa
# # comprobamos q ya son iguales
# k1 <-sapply(trainN, class)
# k2 <-sapply(testN, class)
# kk <-data.frame(k1,k2, k0=NA, stringsAsFactors = FALSE)
#
# obsoleto
# k1<-as.data.frame(names(trainN))
# names(k1)<-"vars1"
#
# k2<-as.data.frame(names(testN))
# names(k2)<-"vars2"
#  problema de las class de test
# cbind(k1, k2)
# names(trainN[,sapply(trainN,is.factor)])
# names(testN[,sapply(testN,is.factor)])
#
# names(trainN[,sapply(trainN,is.numeric)])
# names(testN[,sapply(testN,is.numeric)])
# Chunk 12
set.seed(pi)
casostest1  <- createDataPartition(myclasse, p=0.6, list = FALSE)
str(casostest1)
train1      <- trainN [casostest1,]  # trainning data set
train2      <- trainN [-casostest1,] # proving data set
# Chunk 13
# library( "randomForest" )
# RandomForest does not work with factosr that have a lot of levels
# so we create a function to select only those fcator variables
# with less than a certain numeber (nl) of levels
# mynl <- 9
# flevels <- function(v, nl = mynl ){
#     if (nlevels(v)< nl) return (TRUE)
#     else return(FALSE)
# }
system.time(
rfo2 <- randomForest( myclasse[casostest1] ~. , data = train1
# rfo2 <- randomForest( myclasse[casostest1] ~. , data = train1[,sapply(train1, flevels)]
# , mtry = 7  # el default es raiz(p)/3, donde p es el num de vars
# , subset = train
, importance=TRUE)
)
# varsinmodel <- names( train1[,sapply(train1, flevels)] )
# Chunk 14
pander(importance(rfo2))
# Chunk 15
varImpPlot(rfo2)
# Chunk 16
train2_prediction <- predict(rfo2, newdata=train2)
kk<-confusionMatrix(train2_prediction, myclasse[-casostest1])
# str(kk)
pander(kk$overall[1:2], caption="overall.")
pander(kk$table, caption="Confusion table.")
pander(t(kk$byClass), caption="model parameters by class.")
# confusionMatrix(train2_prediction, myclasse[-casostest1])$overall['Accuracy']
testN2_prediction <- predict(rfo2, newdata=testN)
testN2_prediction
cbind(test$user_name,testN2_prediction)
cbind(test$user_name,testN2_prediction)
View(test)
data.frame(test$user_name,testN2_prediction)
names(trainN)
