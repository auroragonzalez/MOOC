print(xtable(brnn.final$results, digits = c(3,3,5,5,5,5), caption="BRNN"), comment = F,include.rownames=FALSE)
print(xtable(rf.final$results, digits = c(3,3,5,5,5,5), caption="RF"), comment = F,include.rownames=FALSE)
cat("\\clearpage")
}
f.TOTAL2 <- function(dfentrada, indexx, PCA = T){
df <- dfentrada
df2 <- df[indexx]
dfx <- df2
set.seed(23)
nTraining <- as.integer(nrow(dfx) * 0.75)
indices <- sample(1:nrow(dfx), nTraining)
training <- dfx[indices,]
test <- dfx[-indices,]
trainingData <- training
testData <- test
x <- nearZeroVar(trainingData, saveMetrics = F)
print("Se han borrado las siguientes por tener varianza cercana a cero")
print(rownames(nearZeroVar(trainingData, saveMetrics = T)[nearZeroVar(trainingData, saveMetrics = T)[,"nzv"] > 0, ] ))
trainingData <- trainingData[,-x]
testData <- testData[,-x]
# Standarization of both subsets
procValues <- preProcess(trainingData, method = c("center", "scale"))   #c("range")
trainNormalized <-  predict(procValues, trainingData)
testNormalized <-  predict(procValues, testData)
inputs_train <- subset(trainNormalized,select = -c(EaparcialSUM))
inputs_test <- subset(testNormalized,select = -c(EaparcialSUM))
output_train <- trainingData$EaparcialSUM
output_test <- testData$EaparcialSUM
# Applying PCA with the required number of components to get the 98% of confidence
set.seed(123)
transformador.pca <- preProcess(
inputs_train,
method = c("pca"),
thres = 0.98
)
if(PCA){
train.pca <- predict(transformador.pca, inputs_train)
test.pca <- predict(transformador.pca, inputs_test)
}
if(!PCA){
train.pca <- inputs_train
test.pca <- inputs_test
}
# Transformation of the training and test data into the PCA components
#
train.pca.completo <- cbind(train.pca, output_train)
test.pca.completo <- cbind(test.pca, output_test)
# Use t-times k-fold validation, with t = 5 and k = 10 (by default)
ctrl <- trainControl(method = "repeatedcv", repeats = 5, returnResamp = "all")
paramGrid <- expand.grid(.sigma = c(0.0005,0.01,0.05,0.08,0.1, 0.5, 1))
set.seed(23)
# Find the optimum combination of parameters
gauss.final <- caret::train(
output_train~., # We want to predict Temp_Comfort3B according to the predictors
data = train.pca.completo, # Inputs + Outputs
method = "gaussprRadial",
metric = "RMSE", # Metric to evaluate
tuneGrid = paramGrid, # Parameters for tunning
trControl = ctrl # Parameters of control
)
gauss.final.resamples.RMSE <- gauss.final$resample$RMSE
gauss.final.resamples.sigma <- factor(gauss.final$resample$sigma)
gauss.final.resamples.pliegue <- factor(gauss.final$resample$Resample)
gauss.final.resamples.frame <- data.frame(cbind(gauss.final.resamples.pliegue, gauss.final.resamples.sigma, gauss.final.resamples.RMSE))
colnames(gauss.final.resamples.frame) <- c("pliegue", "sigma", "RMSE")
# Random Forest
paramGrid <- expand.grid(.mtry = c(1:10))
set.seed(23)
# Find the optimum combination of parameters
rf.final <- caret::train(
output_train~., # We want to predict ENERGY_METER according to the predictors
data = train.pca.completo, # Inputs + Outputs
method = "rf",
metric = "RMSE", # Metric to evaluate
tuneGrid = paramGrid, # Parameters for tunning
trControl = ctrl, # Parameters of control
preProc = c("center", "scale")
)
rf.final.resamples.RMSE <- rf.final$resample$RMSE
rf.final.resamples.mtry <- factor(rf.final$resample$mtry)
rf.final.resamples.pliegue <- factor(rf.final$resample$Resample)
rf.final.resamples.frame <- data.frame(cbind(rf.final.resamples.pliegue, rf.final.resamples.mtry, rf.final.resamples.RMSE))
colnames(rf.final.resamples.frame) <- c("pliegue", "mtry", "RMSE")
#
########### 2. MLP #####################
# Find the optimum combination of parameters
paramGrid <- expand.grid(.size = c(34:40,50,60,65,70))
set.seed(23)
# Buscamos la mejor combinación de parámetros
mlp.final <- caret::train(
output_train~., # We want to predict Temp_Comfort3B according to the predictors
data = train.pca.completo, # Inputs + Outputs
method = "mlp",
metric = "RMSE",
tuneGrid = paramGrid,
trControl = ctrl,
learnFunc = "Rprop"
)
mlp.final.resamples.RMSE <- mlp.final$resample$RMSE
mlp.final.resamples.size <- factor(mlp.final$resample$size)
mlp.final.resamples.pliegue <- factor(mlp.final$resample$Resample)
mlp.final.resamples.frame <- data.frame(cbind(mlp.final.resamples.pliegue, mlp.final.resamples.size, mlp.final.resamples.RMSE))
colnames(mlp.final.resamples.frame) <- c("pliegue", "size", "RMSE")
########### 3. SVM #####################
# Grid with the parameters to assess
set.seed(23)
paramGrid <- expand.grid(.C = c(1:15,18,20,22))
# Find the optimum combination of parameters
svm.final <- caret::train(
output_train~., # We want to predict Temp_Comfort3B according to the predictors
data = train.pca.completo, # Inputs + Outputs
method = "svmRadialCost",
metric = "RMSE", # Metric to evaluate
tuneGrid = paramGrid, # Parameters for tunning
trControl = ctrl, # Parameters of control
preProc = c("center", "scale")
)
svm.final.resamples.RMSE <- svm.final$resample$RMSE
svm.final.resamples.C <- factor(svm.final$resample$C)
svm.final.resamples.pliegue <- factor(svm.final$resample$Resample)
svm.final.resamples.frame <- data.frame(cbind(svm.final.resamples.pliegue, svm.final.resamples.C, svm.final.resamples.RMSE))
colnames(svm.final.resamples.frame) <- c("pliegue", "C", "RMSE")
########### 4. BRNN #####################
set.seed(23)
paramGrid <- expand.grid(.neurons = c(1,2,3,4,5,10,20))
# Find the optimum combination of parameters
brnn.final <- caret::train(
output_train~., # We want to predict Temp_Comfort3B according to the predictors
data = train.pca.completo, # Inputs + Outputs
method = "brnn",
metric = "RMSE", # Metric to evaluate
tuneGrid = paramGrid, # Parameters for tunning
trControl = ctrl # Parameters of control
)
brnn.final.resamples.RMSE <- brnn.final$resample$RMSE
brnn.final.resamples.neurons <- factor(brnn.final$resample$neurons)
brnn.final.resamples.pliegue <- factor(brnn.final$resample$Resample)
brnn.final.resamples.frame <- data.frame(cbind(brnn.final.resamples.pliegue, brnn.final.resamples.neurons, brnn.final.resamples.RMSE))
colnames(brnn.final.resamples.frame) <- c("pliegue", "neurons", "RMSE")
##################################################################################
grouping <- c(rep("Gauss RBF", 50), rep("MLP", 50), rep("SVM", 50),  rep("Bayesian NN", 50))
grouping.factor <- factor(grouping)
outcome <- c(gauss.final.resamples.RMSE, mlp.final.resamples.RMSE, svm.final.resamples.RMSE, brnn.final.resamples.RMSE)
gauss.final.prediction <- predict(gauss.final, test.pca)
gauss.final.rmse <- RMSE(gauss.final.prediction, output_test, na.rm = FALSE)
gauss.final.r2 <- R2(gauss.final.prediction, output_test, formula = "corr", na.rm = FALSE)
mlp.final.prediction <- predict(mlp.final, test.pca)
mlp.final.rmse <- RMSE(mlp.final.prediction, output_test, na.rm = FALSE)
mlp.final.r2 <- R2(mlp.final.prediction, output_test, formula = "corr", na.rm = FALSE)
svm.final.prediction <- predict(svm.final, test.pca)
svm.final.rmse <- RMSE(svm.final.prediction, output_test, na.rm = FALSE)
svm.final.r2 <- R2(svm.final.prediction, output_test, formula = "corr", na.rm = FALSE)
brnn.final.prediction <- predict(brnn.final, test.pca)
brnn.final.rmse <- RMSE(brnn.final.prediction, output_test, na.rm = FALSE)
brnn.final.r2 <- R2(brnn.final.prediction, output_test, formula = "corr", na.rm = FALSE)
rf.final.prediction <- predict(rf.final, test.pca)
rf.final.rmse <- RMSE(rf.final.prediction, output_test, na.rm = FALSE)
rf.final.r2 <- R2(rf.final.prediction, output_test, formula = "corr", na.rm = FALSE)
results.rmse <- t(as.matrix(cbind(gauss.final.rmse, mlp.final.rmse, svm.final.rmse, brnn.final.rmse, rf.final.rmse)))
results.r2 <- t(as.matrix(cbind(gauss.final.r2, mlp.final.r2, svm.final.r2, brnn.final.r2, rf.final.r2)))
results.tune <- t(as.matrix(cbind(gauss.final$bestTune, mlp.final$bestTune, svm.final$bestTune, brnn.final$bestTune, rf.final$bestTune)))
results.cvrmse <- results.rmse/mean(output_test)*100
nombres <- c("gauss", "mlp", "svm", "brnn", "rf")
#barplot(results.rmse, main="RMSE using Test data (oC)", xlab="Techniques", col=mypalette, legend = c("Gauss", "MLP", "SVM", "BRNN"), beside=T, xlim = c(0, 10))
#barplot(results.r2, main="R-squared using Test data", xlab="Techniques", col=mypalette, legend = c("Gauss", "MLP", "SVM", "BRNN"), beside=T, xlim = c(0, 10))
# Save outputs:
#save("gauss.final", "mlp.final", "svm.final", "brnn.final", file = "results")
print(xtable(data.frame(nombres, results.tune ,results.rmse,results.cvrmse, results.r2 ), digits = c(5,5,3,5,5,5), caption=""), comment = F,include.rownames=FALSE)
print(names(inputs_test))
print(xtable(gauss.final$results, digits = c(3,3,5,5,5,5), caption="GAUSS"), comment = F,include.rownames=FALSE)
print(xtable(mlp.final$results, digits = c(3,3,5,5,5,5), caption="MLP"), comment = F,include.rownames=FALSE)
print(xtable(svm.final$results, digits = c(3,3,5,5,5,5), caption="SVM"), comment = F,include.rownames=FALSE)
print(xtable(brnn.final$results, digits = c(3,3,5,5,5,5), caption="BRNN"), comment = F,include.rownames=FALSE)
print(xtable(rf.final$results, digits = c(3,3,5,5,5,5), caption="RF"), comment = F,include.rownames=FALSE)
cat("\\clearpage")
}
# Chunk 6
library("xtable")
library(RColorBrewer)
library("caret")
library("plyr")
mypalette<-brewer.pal(6,"Spectral")
df3 <- df3
df3 <- na.omit(df3)
df <- df3
bp <- boxplot(df$EaparcialSUM)
indices <- which(df$EaparcialSUM %in% bp$out)
df <- df[-indices,]
#boxplot(df$EaparcialSUM)
dfentrada <- df
dfentrada$fecha <- as.Date(dfentrada$fecha, format = "%d/%m/%Y")
dfentrada <- dfentrada[dfentrada$fecha >= "2014-12-01",]
ind1 <- list(c(3,4,5,8,135,147))
ind1 <- list(c(3,4,5,8,135,138))
i=1
f.TOTAL(dfentrada,ind1[[i]],PCA=F)
libary("shiny")
libary("shiny")
runExample("01_hello", port=5050)
runExample("01_hello")
libray("shiny")
library("shiny")
runExample("01_hello",port = 80)
runExample("01_hello",port = 5050)
runExample("01_hello",port = 80)
library(caret)
library(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(3433)
IL <- grep("^IL", colnames(training), value=TRUE)
ILpredictors <- predictors[, IL]
dataframe <- data.frame(diagnosis, ILpredictors)
inTrain <- createDataPartition(dataframe$diagnosis, p=3/4)[[1]]
training <- df[inTrain, ]
testing <- df[-inTrain, ]
dataframe
str(dataframe)
library("caret")
train <- read.table("pml-training.csv", header = T, sep = ",", dec=".")
test <- read.table("pml-testing.csv", header = T, sep = ",", dec=".")
sapply(test, function(x) sum(is.na(x)))/nrow(test)*100
sapply(train, function(x) sum(is.na(x)))/nrow(train)*100
index <- as.vector(sapply(train, function(x) sum(is.na(x)))/nrow(test)*100!=0)
train2 <- train[!index]
test2 <- test[!index]
setwd("~/Dropbox/COURSERA-PracticalMachinelearning/Peer_Assignment_AURORA")
library("caret")
train <- read.table("pml-training.csv", header = T, sep = ",", dec=".")
test <- read.table("pml-testing.csv", header = T, sep = ",", dec=".")
sapply(test, function(x) sum(is.na(x)))/nrow(test)*100
sapply(train, function(x) sum(is.na(x)))/nrow(train)*100
index <- as.vector(sapply(train, function(x) sum(is.na(x)))/nrow(test)*100!=0)
train2 <- train[!index]
test2 <- test[!index]
procValues <- preProcess(train2, method = c("center", "scale"))
trainNormalized <- predict(procValues, train2)
testNormalized <- predict(procValues, test2)
inputs_train <- subset(trainNormalized, select = -c(classe))
inputs_test <- subset(testNormalized, select = -c(problem_id))
output_train <- trainNormalized["classe"]
precPCA <- preProcess(inputs_train[,1:ncol(inputs_train)-1], method = "pca",thresh = 0.8)
inputs_trainPCA <- predict(precPCA,  inputs_train )
inputs_testPCA <- predict(precPCA, inputs_test )
?trainControl
set.seed(1234)
ctrl <- trainControl(method = "cv"#, repeats = 5
set.seed(1234)
ctrl <- trainControl(method = "cv"#, repeats = 5
, returnResamp = "all")
nTraining <- as.integer(nrow(inputs_trainPCA) * 0.6)
indices <- sample(1:nrow(inputs_trainPCA), nTraining)
train3 <- cbind(inputs_trainPCA[indices,], classe = output_train[indices,])
test3 <- cbind(inputs_trainPCA[-indices,], classe = output_train[-indices,])
names(train3)
rf.final <- caret::train(
classe~.,
data = train3, # Inputs + Outputs
method = "rf",
#  metric = "Accuracy", # Metric to evaluate
# tuneGrid = paramGrid, # Parameters for tunning
trControl = ctrl # Parameters of control
)
dbExistsTable(con, "Facultad_Quimica")
rf.final
save(rf.final, file = "my_model1.rda")
load("my_model1.rda")
getwd
getwd()
rf.pred <- predict(rf.final, test3)
rf.pred
confusionMatrix(test3$classe, rf.pred)$overall['Accuracy']
rf.final
train <- read.table("pml-training.csv", header = T, sep = ",", dec=".")
test <- read.table("pml-testing.csv", header = T, sep = ",", dec=".")
print(xtable(summary(train)))
library("xtable")
print(xtable(summary(train)))
summary(train)
head(train)
head(test)
sapply(test, function(x) sum(is.na(x)))/nrow(test)*100
sapply(train, function(x) sum(is.na(x)))/nrow(train)*100
index <- as.vector(sapply(train, function(x) sum(is.na(x)))/nrow(test)*100!=0)
train2 <- train[!index]
test2 <- test[!index]
procValues <- preProcess(train2, method = c("center", "scale"))
trainNormalized <- predict(procValues, train2)
testNormalized <- predict(procValues, test2)
trainNormalized["classe"]
inputs_train
dim(inputs_train)
dim(train2)
dim(train)
precPCA <- preProcess(inputs_train[,1:ncol(inputs_train)-1], method = "pca",thresh = 0.8)
inputs_trainPCA <- predict(precPCA,  inputs_train )
inputs_testPCA <- predict(precPCA, inputs_test )
dim(inputs_trainPCA)
rf.predF <- predict(rf.final, inputs_test)
head(inputs_test)
rf.predF <- predict(rf.final, inputs_testPCA)
head(test3)
head(inputs_testPCA)
inputs_trainPCA <- predict(precPCA,  inputs_train )
inputs_testPCA <- predict(precPCA, inputs_test )
head(inputs_trainPCA)
head(test3)
summary(test3)
rf.predF <- predict(rf.final, inputs_testPCA)
summary(test3)
summary(inputs_testPCA)
library("caret")
library("xtable")
train <- read.table("pml-training.csv", header = T, sep = ",", dec=".")
test <- read.table("pml-testing.csv", header = T, sep = ",", dec=".")
head(train)
head(test)
sapply(test, function(x) sum(is.na(x)))/nrow(test)*100
sapply(train, function(x) sum(is.na(x)))/nrow(train)*100
index <- as.vector(sapply(train, function(x) sum(is.na(x)))/nrow(test)*100!=0)
train2 <- train[!index]
test2 <- test[!index]
procValues <- preProcess(train2, method = c("center", "scale"))
trainNormalized <- predict(procValues, train2)
testNormalized <- predict(procValues, test2)
inputs_train <- subset(trainNormalized, select = -c(classe))   # get rid of the classe
inputs_test <- subset(testNormalized, select = -c(problem_id))  # get rid of the id
output_train <- trainNormalized["classe"]
dim(inputs_train)
precPCA <- preProcess(inputs_train[,1:ncol(inputs_train)-1], method = "pca",thresh = 0.8)
inputs_trainPCA <- predict(precPCA,  inputs_train )
inputs_testPCA <- predict(precPCA, inputs_test )
inputs_trainPCA
names(inputs_trainPCA)
str(inputs_trainPCA)
View(inputs_testPCA)
library("caret")
library("xtable")
train <- read.table("pml-training.csv", header = T, sep = ",", dec=".")
test <- read.table("pml-testing.csv", header = T, sep = ",", dec=".")
View(test)
head(train)
head(test)
sapply(test, function(x) sum(is.na(x)))/nrow(test)*100
sapply(train, function(x) sum(is.na(x)))/nrow(train)*100
index <- as.vector(sapply(train, function(x) sum(is.na(x)))/nrow(test)*100!=0)
train2 <- train[!index]
test2 <- test[!index]
names(train2)
names(train2)==names(test2)
View(test2)
index
procValues <- preProcess(train2, method = c("center", "scale"))
trainNormalized <- predict(procValues, train2)
testNormalized <- predict(procValues, test2)
View(test2)
View(inputs_test)
View(inputs_train)
sapply(test, function(x) sum(is.na(x)))/nrow(test)*100
sapply(train, function(x) sum(is.na(x)))/nrow(train)*100
index <- as.vector(sapply(train, function(x) sum(is.na(x)))/nrow(test)*100!=0)
train[!index]
train2 <- train[!index]
View(train2)
summary(test3)
summary(inputs_testPCA)
train3
head(train3)
as.data.frame(names(train3))
train3[38:51]
head(train3[38:51])
rf.final <- caret::train(
classe~.,
data = train3[38:52], # Inputs + Outputs
method = "rf",
#  metric = "Accuracy", # Metric to evaluate
# tuneGrid = paramGrid, # Parameters for tunning
trControl = ctrl # Parameters of control
)
rf.final
precPCA <- preProcess(inputs_train[,1:ncol(inputs_train)-1], method = "pca",thresh = 0.9)
inputs_trainPCA <- predict(precPCA,  inputs_train )
inputs_testPCA <- predict(precPCA, inputs_test )
set.seed(1234)
ctrl <- trainControl(method = "cv", repeats = 5
, returnResamp = "all")
nTraining <- as.integer(nrow(inputs_trainPCA) * 0.6)
indices <- sample(1:nrow(inputs_trainPCA), nTraining)
train3 <- cbind(inputs_trainPCA[indices,], classe = output_train[indices,])
test3 <- cbind(inputs_trainPCA[-indices,], classe = output_train[-indices,])
head(train3)
21-14
head(train3[38:59])
paramGrid <- expand.grid(.mtry = c(3,5,10,15))
set.seed(1234)
rf.final <- caret::train(
classe~.,
data = train3[38:59], # Inputs + Outputs
method = "rf",
metric = "Accuracy", # Metric to evaluate
tuneGrid = paramGrid, # Parameters for tunning
trControl = ctrl # Parameters of control
)
head(train3[38:59])
rf.final
paramGrid <- expand.grid(.mtry = c(2,3,4,5,10,15))
set.seed(1234)
rf.final <- caret::train(
classe~.,
data = train3[38:59], # Inputs + Outputs
method = "rf",
metric = "Accuracy", # Metric to evaluate
tuneGrid = paramGrid, # Parameters for tunning
trControl = ctrl # Parameters of control
)
save(rf.final, file = "my_model2.rda")
load("my_model2.rda")
library("xtable")
source("../../../functions/fFA.R")
extractdate <- function(date) {
day <- format(date, format="%d")
month <- format(date, format="%m")
year <- format(date, format="%Y")
date <- paste0(year,"-", month, "-", day)
cbind(date)
}
f.fromPentahoToHourlyData <- function(dfT, vble="temp"){
dfT <- dfT[3:4]
names(dfT) <- c("Fecha", vble)
dfT$Fecha = as.POSIXlt(dfT$Fecha)
dfT$hour <- format(dfT$Fecha, "%H")
dfT$date <- extractdate(dfT$Fecha)
dias <- levels(factor(dfT$date))
dfTfinal <- dfT[c("hour", vble, "date")][1,][-1,]
for(i in 1:length(dias)){
dfaux <- dfT[dfT$date==dias[i],]
aggregate(dfaux[,vble], list(dfaux$hour), mean)
dfTfinal <- rbind(dfTfinal, cbind(aggregate(dfaux[,vble], list(dfaux$hour), mean), dias[i]))
}
dfTfinal$FechaRounded  <- as.POSIXlt(paste(dfTfinal$`dias[i]`, paste0(dfTfinal$Group.1, ":00:00")))+1*60*60
dfTfinal2 <- dfTfinal[c("x", "FechaRounded")]
dfTfinal2$fechaNum <- as.numeric(dfTfinal2$FechaRounded)
dfTfinal2 <- dfTfinal2[-2]
names(dfTfinal2)[1]<- vble
return(dfTfinal2)
}
##Leemos los datos (tanto históricos como holidays)
fichero <- "DispositivosHistoricos_315.csv"
df1 <- read.table(fichero ,header=T,sep=";",dec=".", stringsAsFactors = F)
df <-df1[c("Fecha", "Energia.activa")]
df <- df[-1,]
dfHolidays <- read.table("holidaysChem.csv", header=T, sep=",", dec=".", stringsAsFactors = F)
#Hay que dividir por 1000 proque está en Wh y nosotros queremos KWh
df$Energia.activa <- as.numeric(df$Energia.activa)/1000
df$Fecha = as.POSIXlt(df$Fecha)
# round each 10 minutes
df$FechaRounded<- as.POSIXlt(round(as.double(df$Fecha)/(10*60))*(10*60),origin=(as.POSIXlt('1970-01-01')))
# pick o'clok times
df2 <- df[which(format(df$FechaRounded , "%M")=="00"),]
# find errors (where there is more than 1 hour of difference between observations we select the index and then, after computing the difference we NA the consume)
indices <- which(diff(df2$FechaRounded)!=1)
consumo <- c(NA, diff(df2$Energia.activa))
if(length(indices) >0){
consumo[indices] = NA
}
df2$consumo <- consumo
df2$day <- format(df2$FechaRounded , "%d")
df2$month <- format(df2$FechaRounded , "%m")
df2$season <- as.factor(getSeason(df2$FechaRounded))#, labels = c(1,2,3,4),
df2$fechaNum <- as.numeric(df2$FechaRounded)
# temperatura
dfT <- read.table("temp_213.csv", head=T, skip = 1, sep=";", dec=",", stringsAsFactors = F)
dfT2 <- f.fromPentahoToHourlyData(dfT, "temp")
dfMixed1 <- merge(df2,dfT2, by = c("fechaNum"), sort = F)
# humedad
dfH <- read.table("hum_213.csv", head=T, skip = 1, sep=";", dec=",", stringsAsFactors = F)
dfH2 <- f.fromPentahoToHourlyData(dfH, "hum")
dfMixed1 <- merge(dfMixed1,dfT2, by = c("fechaNum"), sort = F)
# radiacion
dfR <- read.table("rad_213.csv", head=T, skip = 1, sep=";", dec=",", stringsAsFactors = F)
dfR2 <- f.fromPentahoToHourlyData(dfR, "rad")
dfMixed1 <- merge(dfMixed1,dfR2, by = c("fechaNum"), sort = F)
rf.final
save(rf.final, file = "my_model2.rda")
load("my_model2.rda")
rf.final
rf.final
rf.final$bestTune
rf.pred <- predict(rf.final, test3)
confusionMatrix(test3$classe, rf.pred)$overall['Accuracy']
rf.predF <- predict(rf.final, inputs_testPCA)
summary(test3)
rf.predF
rf.predF <- predict(rf.final, inputs_testPCA)
head(test)
test
confusionMatrix(test3$classe, rf.pred)$overall['Accuracy']
save(rf.final, file = "my_model2.rda")
load("my_model2.rda")
rf.final
save(rf.final, file = "my_model2.rda")
head(test)
test <- read.table("pml-testing.csv", header = T, sep = ",", dec=".")
test
rf.predF
