---
title: "Assignment: Prediction Assignment Writeup"
author: "Antonio Maurandi LÃ³pez"
date: "7 de junio de 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, echo=T, results="asis", cahe=TRUE)
options(scipen = 1, digits = 3)  # set default digits

library(pander)
library(caret)

# library(xtable)
# library("lattice")
```

Using devices such as _Jawbone Up_, _Nike FuelBand_, and _Fitbit_ it is now possible to collect a large amount of data about personal activity relatively inexpensively. 

Our goal is to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. 


# Loading and processing the data


Exploration of the data and data structure.

```{r, cache=TRUE}

# download data from the source url
filepath     <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
filepath     <- "pml-training.csv"
train <- read.table(filepath,  sep="," , header=T)
filepath     <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
filepath     <- "pml-testing.csv"
test <- read.table(filepath,  sep="," , header=T)
```

## Missing values: `NA` 

There are variables with a lot of `NA` values, we will use only those variables which are not `NA` always, let set the criteria at 80% of data available, not `NA`.

```{r}
n         <- nrow(train)
f.numofna <- function (vector){
    return( sum(is.na (vector)))
}

x       <- as.vector(apply(train, 2, f.numofna)/n)
table(x)
varsnona <- (x<0.8)

n1 <- length(names(train))
train <- train[,varsnona]
test  <- test[,varsnona]

kk<-lapply(train,data.class)
pander(kk)
n2 <- length(names(train))
```

We will keep `r n2` variables instead of the original `r n1` variables.

## Outcome variable `classe`

It is interesting to check if there are any class more presnet tahn others
```{r}
tt<-table(train$classe)
pander::pander(tt,caption="absolute frecuency of classes of variebl classe")
tt<- prop.table(tt)*100
pander::pander(tt,caption="percentage table")

```

We can see that there are 5 different clasifications and that all of them are arround 16% and 29%


## Standaritation

```{r}
procValues <- preProcess(train, method = c("center", "scale"))
trainN     <- predict(procValues, train)
testN      <- predict(procValues, train)
```

```{r}
train_in      <- subset(trainN, select = -c(classe))    
# test_i      <- subset(testN , select = -c(problem_id)) 
test_in <- testN
# names(testN)
outcome_variable <- trainN["classe"]

dim(train_in)
```



# Model

## Reduction of dimensionality

By means of PCA we will cponsider a problem with a lower dimensionality

```{r}
precPCA     <- preProcess(train_in[,1:ncol(train_in)-1], method = "pca",thresh = 0.9)
train_inPCA <- predict(precPCA,  train_in )
test_inPCA  <- predict(precPCA,  test_in )

```

## Cross validation

We will use a 60% training set, 40% prove set of the total data set with clsification (`classe`).

```{r}
set.seed(pi)
casostest1  <- createDataPartition(outcome_variable$classe, p=0.6, list = FALSE)
train1 <- train_inPCA [casostest1[[1]],] # trainning data set
train2 <- train_inPCA [-casostest1[[1]],] # proving data set
```














This are the outputs of the model:

```{r}
load("my_model2.rda")
rf.final
```

We see that the best `Accuracy` is obtained for mtry = `rf.final$bestTune`, so this one is the chosen one.







## Preprocess


```{r}
zero.var   <- nearZeroVar(df1, saveMetrics=TRUE)
pander(zero.var)
varswithnonzv <- row.names(zero.var[zero.var$nzv==FALSE,])
df1<- df1[,varswithnonzv]
# nrow(df1)
# ncol(df1)
# as.data.frame(names(df1))
classe<- df1$classe
df1<-df1[,-c(2,5)] # quito dos factotes : nombre y time no se q
df1$classe<-NULL   # guardamos la var clasificacion (outcome) en otra yu la quitamos del cto de datos
```

Remove candidate variables with _near zero variance_. 
Now all variables have enough variance.




# `Ramndom Forest`

```{r, cahe=TRUE, eval=FALSE}
library(caret)
set.seed(pi)
fit.rf <-train(classe~., data=dftrai2, method="rf")



library(ElemStatLearn)
data(vowel.train)
data(vowel.test) 
set.seed(33833)
vowel.test$y <- factor(vowel.test$y)
vowel.train$y <- factor(vowel.train$y)
suppressMessages(library(caret))
rfmodel <- suppressMessages(train(y~., data=vowel.train, method="rf"))
```


```{r, eval=FALSE}
# gbmmodel <- suppressMessages(train(y~., data=vowel.train, method="gbm"))

rf.pred <- predict(fit.rf, dftest[,varsnona])
# gbm.result <- predict(gbmmodel, vowel.test)

confusionMatrix(dftrai2$classe, rf.pred)$overall['Accuracy']
```


