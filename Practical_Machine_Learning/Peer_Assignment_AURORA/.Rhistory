brnn.final.r2 <- R2(brnn.final.prediction, output_test, formula = "corr", na.rm = FALSE)
rf.final.prediction <- predict(rf.final, test.pca)
rf.final.rmse <- RMSE(rf.final.prediction, output_test, na.rm = FALSE)
rf.final.r2 <- R2(rf.final.prediction, output_test, formula = "corr", na.rm = FALSE)
results.rmse <- t(as.matrix(cbind(gauss.final.rmse, mlp.final.rmse, svm.final.rmse, brnn.final.rmse, rf.final.rmse)))
results.r2 <- t(as.matrix(cbind(gauss.final.r2, mlp.final.r2, svm.final.r2, brnn.final.r2, rf.final.r2)))
results.tune <- t(as.matrix(cbind(gauss.final$bestTune, mlp.final$bestTune, svm.final$bestTune, brnn.final$bestTune, rf.final$bestTune)))
results.cvrmse <- results.rmse/mean(output_test)*100
nombres <- c("gauss", "mlp", "svm", "brnn", "rf")
#barplot(results.rmse, main="RMSE using Test data (oC)", xlab="Techniques", col=mypalette, legend = c("Gauss", "MLP", "SVM", "BRNN"), beside=T, xlim = c(0, 10))
#barplot(results.r2, main="R-squared using Test data", xlab="Techniques", col=mypalette, legend = c("Gauss", "MLP", "SVM", "BRNN"), beside=T, xlim = c(0, 10))
# Save outputs:
#save("gauss.final", "mlp.final", "svm.final", "brnn.final", file = "results")
print(xtable(data.frame(nombres, results.tune ,results.rmse,results.cvrmse, results.r2 ), digits = c(5,5,3,5,5,5), caption=""), comment = F,include.rownames=FALSE)
print(names(inputs_test))
print(xtable(gauss.final$results, digits = c(3,3,5,5,5,5), caption="GAUSS"), comment = F,include.rownames=FALSE)
print(xtable(mlp.final$results, digits = c(3,3,5,5,5,5), caption="MLP"), comment = F,include.rownames=FALSE)
print(xtable(svm.final$results, digits = c(3,3,5,5,5,5), caption="SVM"), comment = F,include.rownames=FALSE)
print(xtable(brnn.final$results, digits = c(3,3,5,5,5,5), caption="BRNN"), comment = F,include.rownames=FALSE)
print(xtable(rf.final$results, digits = c(3,3,5,5,5,5), caption="RF"), comment = F,include.rownames=FALSE)
cat("\\clearpage")
}
# Chunk 6
library("xtable")
library(RColorBrewer)
library("caret")
library("plyr")
mypalette<-brewer.pal(6,"Spectral")
df3 <- df2
df3 <- na.omit(df3)
df <- df3
bp <- boxplot(df$EaparcialSUM)
indices <- which(df$EaparcialSUM %in% bp$out)
df <- df[-indices,]
#boxplot(df$EaparcialSUM)
dfentrada <- df
dfentrada$fecha <- as.Date(dfentrada$fecha, format = "%d/%m/%Y")
dfentrada <- dfentrada[dfentrada$fecha >= "2014-12-01",]
ind1 <- list(c(3,4,5,8,135,138))
i=1
ind1 <- list(c(3,4,5,8,135,138))
f.TOTAL(dfentrada,ind1[[i]],PCA=F)
# Chunk 1
library("xtable")
library("plyr")
library("pastecs")
library("FactoMineR")
source("../../../../functions/f.descriptivosCONT.R")
fichero <- "Todos_DispositivosHistoricos_105_anio_2015.csv"
library(doParallel)
registerDoParallel(4)
# Chunk 2
df <- read.table(file = "../../../../outside_temperature/IMIDA/calculos/ConsTemp3.csv", sep = ";", header = T, dec = ".", stringsAsFactors = F)
# Chunk 3
for(i in 1: nrow(df)){
df$tmed[i] <- (df$tmed.8[i]+ df$tmed.7[i]+df$tmed.6[i]+df$tmed.5[i]+df$tmed.4[i]+df$tmed.3[i]+ df$tmed.2[i]+df$tmed.1[i]+df$tmed.0[i])/9
df$tmax[i] <- (df$tmax.8[i]+ df$tmax.7[i]+df$tmax.6[i]+df$tmax.5[i]+df$tmax.4[i]+df$tmax.3[i]+ df$tmax.2[i]+df$tmax.1[i]+df$tmax.0[i])/9
df$tmin[i] <- (df$tmin.8[i]+ df$tmin.7[i]+df$tmin.6[i]+df$tmin.5[i]+df$tmin.4[i]+df$tmin.3[i]+ df$tmin.2[i]+df$tmin.1[i]+df$tmin.0[i])/9
df$hrmed[i] <- (df$hrmed.8[i]+ df$hrmed.7[i]+df$hrmed.6[i]+df$hrmed.5[i]+df$hrmed.4[i]+df$hrmed.3[i]+ df$hrmed.2[i]+df$hrmed.1[i]+df$hrmed.0[i])/9
df$hrmax[i] <- (df$hrmax.8[i]+ df$hrmax.7[i]+df$hrmax.6[i]+df$hrmax.5[i]+df$hrmax.4[i]+df$hrmax.3[i]+ df$hrmax.2[i]+df$hrmax.1[i]+df$hrmax.0[i])/9
df$hrmin[i] <- (df$hrmin.8[i]+ df$hrmin.7[i]+df$hrmin.6[i]+df$hrmin.5[i]+df$hrmin.4[i]+df$hrmin.3[i]+ df$hrmin.2[i]+df$hrmin.1[i]+df$hrmin.0[i])/9
df$radmed[i] <- (df$radmed.8[i]+ df$radmed.7[i]+df$radmed.6[i]+df$radmed.5[i]+df$radmed.4[i]+df$radmed.3[i]+ df$radmed.2[i]+df$radmed.1[i]+df$radmed.0[i])/9
df$radmax[i] <- (df$radmax.8[i]+ df$radmax.7[i]+df$radmax.6[i]+df$radmax.5[i]+df$radmax.4[i]+df$radmax.3[i]+ df$radmax.2[i]+df$radmax.1[i]+df$radmax.0[i])/9
df$vvmed[i] <- (df$vvmed.8[i]+ df$vvmed.7[i]+df$vvmed.6[i]+df$vvmed.5[i]+df$vvmed.4[i]+df$vvmed.3[i]+ df$vvmed.2[i]+df$vvmed.1[i]+df$vvmed.0[i])/9
df$vvmax[i] <- (df$vvmax.8[i]+ df$vvmax.7[i]+df$vvmax.6[i]+df$vvmax.5[i]+df$vvmax.4[i]+df$vvmax.3[i]+ df$vvmax.2[i]+df$vvmax.1[i]+df$vvmax.0[i])/9
df$dvmed[i] <- (df$dvmed.8[i]+ df$dvmed.7[i]+df$dvmed.6[i]+df$dvmed.5[i]+df$dvmed.4[i]+df$dvmed.3[i]+ df$dvmed.2[i]+df$dvmed.1[i]+df$dvmed.0[i])/9
df$prec[i] <- (df$prec.8[i]+ df$prec.7[i]+df$prec.6[i]+df$prec.5[i]+df$prec.4[i]+df$prec.3[i]+ df$prec.2[i]+df$prec.1[i]+df$prec.0[i])/9
df$dewpt[i] <- (df$dewpt.8[i]+ df$dewpt.7[i]+df$dewpt.6[i]+df$dewpt.5[i]+df$dewpt.4[i]+df$dewpt.3[i]+ df$dewpt.2[i]+df$dewpt.1[i]+df$dewpt.0[i])/9
df$dpv[i] <- (df$dpv.8[i]+ df$dpv.7[i]+df$dpv.6[i]+df$dpv.5[i]+df$dpv.4[i]+df$dpv.3[i]+ df$dpv.2[i]+df$dpv.1[i]+df$dpv.0[i])/9
df$tmedsin0[i] <- (df$tmed.8[i]+ df$tmed.7[i]+df$tmed.6[i]+df$tmed.5[i]+df$tmed.4[i]+df$tmed.3[i]+ df$tmed.2[i]+df$tmed.1[i])/8
df$tmaxsin0[i] <- (df$tmax.8[i]+ df$tmax.7[i]+df$tmax.6[i]+df$tmax.5[i]+df$tmax.4[i]+df$tmax.3[i]+ df$tmax.2[i]+df$tmax.1[i])/8
df$tminsin0[i] <- (df$tmin.8[i]+ df$tmin.7[i]+df$tmin.6[i]+df$tmin.5[i]+df$tmin.4[i]+df$tmin.3[i]+ df$tmin.2[i]+df$tmin.1[i])/8
df$hrmedsin0[i] <- (df$hrmed.8[i]+ df$hrmed.7[i]+df$hrmed.6[i]+df$hrmed.5[i]+df$hrmed.4[i]+df$hrmed.3[i]+ df$hrmed.2[i]+df$hrmed.1[i])/8
df$hrmaxsin0[i] <- (df$hrmax.8[i]+ df$hrmax.7[i]+df$hrmax.6[i]+df$hrmax.5[i]+df$hrmax.4[i]+df$hrmax.3[i]+ df$hrmax.2[i]+df$hrmax.1[i])/8
df$hrminsin0[i] <- (df$hrmin.8[i]+ df$hrmin.7[i]+df$hrmin.6[i]+df$hrmin.5[i]+df$hrmin.4[i]+df$hrmin.3[i]+ df$hrmin.2[i]+df$hrmin.1[i])/8
df$radmedsin0[i] <- (df$radmed.8[i]+ df$radmed.7[i]+df$radmed.6[i]+df$radmed.5[i]+df$radmed.4[i]+df$radmed.3[i]+ df$radmed.2[i]+df$radmed.1[i])/8
df$radmaxsin0[i] <- (df$radmax.8[i]+ df$radmax.7[i]+df$radmax.6[i]+df$radmax.5[i]+df$radmax.4[i]+df$radmax.3[i]+ df$radmax.2[i]+df$radmax.1[i])/8
df$vvmedsin0[i] <- (df$vvmed.8[i]+ df$vvmed.7[i]+df$vvmed.6[i]+df$vvmed.5[i]+df$vvmed.4[i]+df$vvmed.3[i]+ df$vvmed.2[i]+df$vvmed.1[i])/8
df$vvmaxsin0[i] <- (df$vvmax.8[i]+ df$vvmax.7[i]+df$vvmax.6[i]+df$vvmax.5[i]+df$vvmax.4[i]+df$vvmax.3[i]+ df$vvmax.2[i]+df$vvmax.1[i])/8
df$vvmax[i] <- (df$vvmax.8[i]+ df$vvmax.7[i]+df$vvmax.6[i]+df$vvmax.5[i]+df$vvmax.4[i]+df$vvmax.3[i]+ df$vvmax.2[i]+df$vvmax.1[i])/8
df$dvmedsin0[i] <- (df$dvmed.8[i]+ df$dvmed.7[i]+df$dvmed.6[i]+df$dvmed.5[i]+df$dvmed.4[i]+df$dvmed.3[i]+ df$dvmed.2[i]+df$dvmed.1[i])/8
df$precsin0[i] <- (df$prec.8[i]+ df$prec.7[i]+df$prec.6[i]+df$prec.5[i]+df$prec.4[i]+df$prec.3[i]+ df$prec.2[i]+df$prec.1[i])/8
df$dewptsin0[i] <- (df$dewpt.8[i]+ df$dewpt.7[i]+df$dewpt.6[i]+df$dewpt.5[i]+df$dewpt.4[i]+df$dewpt.3[i]+ df$dewpt.2[i]+df$dewpt.1[i])/8
df$dpvsin0[i] <- (df$dpv.8[i]+ df$dpv.7[i]+df$dpv.6[i]+df$dpv.5[i]+df$dpv.4[i]+df$dpv.3[i]+ df$dpv.2[i]+df$dpv.1[i])/8
}
for(i in 1: nrow(df)){
df$tmedBQ1[i] <- (df$tmed.8[i]+ df$tmed.7[i]+df$tmed.6[i]+df$tmed.5[i])/4
df$tmedBQ2[i] <- (df$tmed.4[i]+df$tmed.3[i]+ df$tmed.2[i]+df$tmed.1[i]+df$tmed.0[i])/5
df$tmaxBQ1[i] <- (df$tmax.8[i]+ df$tmax.7[i]+df$tmax.6[i]+df$tmax.5[i])/4
df$tmaxBQ2[i] <- (df$tmax.4[i]+df$tmax.3[i]+ df$tmax.2[i]+df$tmax.1[i]+df$tmax.0[i])/5
df$tminBQ1[i] <- (df$tmin.8[i]+ df$tmin.7[i]+df$tmin.6[i]+df$tmin.5[i])/4
df$tminBQ2[i] <- (df$tmin.4[i]+df$tmin.3[i]+ df$tmin.2[i]+df$tmin.1[i]+df$tmin.0[i])/5
df$hrmedBQ1[i] <- (df$hrmed.8[i]+ df$hrmed.7[i]+df$hrmed.6[i]+df$hrmed.5[i])/4
df$hrmedBQ2[i] <- (df$hrmed.4[i]+df$hrmed.3[i]+ df$hrmed.2[i]+df$hrmed.1[i]+df$hrmed.0[i])/5
df$hrmaxBQ1[i] <- (df$hrmax.8[i]+ df$hrmax.7[i]+df$hrmax.6[i]+df$hrmax.5[i])/4
df$hrmaxBQ2[i] <- (df$hrmax.4[i]+df$hrmax.3[i]+ df$hrmax.2[i]+df$hrmax.1[i]+df$hrmax.0[i])/5
df$hrminBQ1[i] <- (df$hrmin.8[i]+ df$hrmin.7[i]+df$hrmin.6[i]+df$hrmin.5[i])/4
df$hrminBQ2[i] <- (df$hrmin.4[i]+df$hrmin.3[i]+ df$hrmin.2[i]+df$hrmin.1[i]+df$hrmin.0[i])/5
df$radmedBQ1[i] <- (df$radmed.8[i]+ df$radmed.7[i]+df$radmed.6[i]+df$radmed.5[i])/4
df$radmedBQ2[i] <- (df$radmed.4[i]+df$radmed.3[i]+ df$radmed.2[i]+df$radmed.1[i]+df$radmed.0[i])/5
df$radmaxBQ1[i] <- (df$radmax.8[i]+ df$radmax.7[i]+df$radmax.6[i]+df$radmax.5[i])/4
df$radmaxBQ2[i] <- (df$radmax.4[i]+df$radmax.3[i]+ df$radmax.2[i]+df$radmax.1[i]+df$radmax.0[i])/5
df$vvmedBQ1[i] <- (df$vvmed.8[i]+ df$vvmed.7[i]+df$vvmed.6[i]+df$vvmed.5[i])/4
df$vvmedBQ2[i] <- (df$vvmed.4[i]+df$vvmed.3[i]+ df$vvmed.2[i]+df$vvmed.1[i]+df$vvmed.0[i])/5
df$vvmaxBQ1[i] <- (df$vvmax.8[i]+ df$vvmax.7[i]+df$vvmax.6[i]+df$vvmax.5[i])/4
df$vvmaxBQ1[i] <- (df$vvmax.4[i]+df$vvmax.3[i]+ df$vvmax.2[i]+df$vvmax.1[i]+df$vvmax.0[i])/5
df$dvmedBQ1[i] <- (df$dvmed.8[i]+ df$dvmed.7[i]+df$dvmed.6[i]+df$dvmed.5[i])/4
df$dvmedBQ2[i] <- (df$dvmed.4[i]+df$dvmed.3[i]+ df$dvmed.2[i]+df$dvmed.1[i]+df$dvmed.0[i])/5
df$dewptBQ1[i] <- (df$dewpt.8[i]+ df$dewpt.7[i]+df$dewpt.6[i]+df$dewpt.5[i])/4
df$dewptBQ2[i] <- (df$dewpt.4[i]+df$dewpt.3[i]+ df$dewpt.2[i]+df$dewpt.1[i]+df$dewpt.0[i])/5
df$dpvBQ1[i] <- (df$dpv.8[i]+ df$dpv.7[i]+df$dpv.6[i]+df$dpv.5[i])/4
df$dpvBQ2[i] <- (df$dpv.4[i]+df$dpv.3[i]+ df$dpv.2[i]+df$dpv.1[i]+df$dpv.0[i])/5
}
#df <- df[-c(20,34,48,62,76,90,104,118, 132,146,160)]
df$dia <- as.integer(revalue(df$dia, c("lunes"=1, "martes"=2, "miércoles"=3,"jueves"=4,  "viernes"=5, "sábado" = 6, "domingo" = 7)))
df$mes <- as.integer(revalue(df$mes, c("enero"=1, "febrero"=2, "marzo"=3,"abril"=4,  "mayo"=5, "junio"=6, "julio"=7, "agosto"=8, "septiembre"=9, "octubre"=10, "noviembre"=11, "diciembre"=12)))
df$season <- as.numeric(factor(df$season, levels= c("spring", "summer", "fall", "winter"), labels = c(1,2,3,4)))
# Chunk 4
df1 <- df[df$momento==1,]
df2 <- df[df$momento==2,]
df3 <- df[df$momento==3,]
# Chunk 5
f.TOTAL <- function(dfentrada, indexx, PCA = T){
df <- dfentrada
df2 <- df[indexx]
dfx <- df2
set.seed(23)
nTraining <- as.integer(nrow(dfx) * 0.75)
indices <- sample(1:nrow(dfx), nTraining)
training <- dfx[indices,]
test <- dfx[-indices,]
trainingData <- training
testData <- test
# Standarization of both subsets
procValues <- preProcess(trainingData, method = c("center", "scale"))   #c("range")
trainNormalized <-  predict(procValues, trainingData)
testNormalized <-  predict(procValues, testData)
inputs_train <- subset(trainNormalized,select = -c(EaparcialSUM))
inputs_test <- subset(testNormalized,select = -c(EaparcialSUM))
output_train <- trainingData$EaparcialSUM
output_test <- testData$EaparcialSUM
# Applying PCA with the required number of components to get the 98% of confidence
set.seed(123)
transformador.pca <- preProcess(
inputs_train,
method = c("pca"),
thres = 0.98
)
if(PCA){
train.pca <- predict(transformador.pca, inputs_train)
test.pca <- predict(transformador.pca, inputs_test)
}
if(!PCA){
train.pca <- inputs_train
test.pca <- inputs_test
}
# Transformation of the training and test data into the PCA components
#
train.pca.completo <- cbind(train.pca, output_train)
test.pca.completo <- cbind(test.pca, output_test)
# Use t-times k-fold validation, with t = 5 and k = 10 (by default)
ctrl <- trainControl(method = "repeatedcv", repeats = 5, returnResamp = "all")
paramGrid <- expand.grid(.sigma = c(0.0005,0.01,0.05,0.08,0.1, 0.5, 1))
set.seed(23)
# Find the optimum combination of parameters
gauss.final <- caret::train(
output_train~., # We want to predict Temp_Comfort3B according to the predictors
data = train.pca.completo, # Inputs + Outputs
method = "gaussprRadial",
metric = "RMSE", # Metric to evaluate
tuneGrid = paramGrid, # Parameters for tunning
trControl = ctrl # Parameters of control
)
gauss.final.resamples.RMSE <- gauss.final$resample$RMSE
gauss.final.resamples.sigma <- factor(gauss.final$resample$sigma)
gauss.final.resamples.pliegue <- factor(gauss.final$resample$Resample)
gauss.final.resamples.frame <- data.frame(cbind(gauss.final.resamples.pliegue, gauss.final.resamples.sigma, gauss.final.resamples.RMSE))
colnames(gauss.final.resamples.frame) <- c("pliegue", "sigma", "RMSE")
# Random Forest
paramGrid <- expand.grid(.mtry = c(1:10))
set.seed(23)
# Find the optimum combination of parameters
rf.final <- caret::train(
output_train~., # We want to predict ENERGY_METER according to the predictors
data = train.pca.completo, # Inputs + Outputs
method = "rf",
metric = "RMSE", # Metric to evaluate
tuneGrid = paramGrid, # Parameters for tunning
trControl = ctrl, # Parameters of control
preProc = c("center", "scale")
)
rf.final.resamples.RMSE <- rf.final$resample$RMSE
rf.final.resamples.mtry <- factor(rf.final$resample$mtry)
rf.final.resamples.pliegue <- factor(rf.final$resample$Resample)
rf.final.resamples.frame <- data.frame(cbind(rf.final.resamples.pliegue, rf.final.resamples.mtry, rf.final.resamples.RMSE))
colnames(rf.final.resamples.frame) <- c("pliegue", "mtry", "RMSE")
#
########### 2. MLP #####################
# Find the optimum combination of parameters
paramGrid <- expand.grid(.size = c(34:40,50,60,65,70))
set.seed(23)
# Buscamos la mejor combinación de parámetros
mlp.final <- caret::train(
output_train~., # We want to predict Temp_Comfort3B according to the predictors
data = train.pca.completo, # Inputs + Outputs
method = "mlp",
metric = "RMSE",
tuneGrid = paramGrid,
trControl = ctrl,
learnFunc = "Rprop"
)
mlp.final.resamples.RMSE <- mlp.final$resample$RMSE
mlp.final.resamples.size <- factor(mlp.final$resample$size)
mlp.final.resamples.pliegue <- factor(mlp.final$resample$Resample)
mlp.final.resamples.frame <- data.frame(cbind(mlp.final.resamples.pliegue, mlp.final.resamples.size, mlp.final.resamples.RMSE))
colnames(mlp.final.resamples.frame) <- c("pliegue", "size", "RMSE")
########### 3. SVM #####################
# Grid with the parameters to assess
set.seed(23)
paramGrid <- expand.grid(.C = c(1:15,18,20,22))
# Find the optimum combination of parameters
svm.final <- caret::train(
output_train~., # We want to predict Temp_Comfort3B according to the predictors
data = train.pca.completo, # Inputs + Outputs
method = "svmRadialCost",
metric = "RMSE", # Metric to evaluate
tuneGrid = paramGrid, # Parameters for tunning
trControl = ctrl, # Parameters of control
preProc = c("center", "scale")
)
svm.final.resamples.RMSE <- svm.final$resample$RMSE
svm.final.resamples.C <- factor(svm.final$resample$C)
svm.final.resamples.pliegue <- factor(svm.final$resample$Resample)
svm.final.resamples.frame <- data.frame(cbind(svm.final.resamples.pliegue, svm.final.resamples.C, svm.final.resamples.RMSE))
colnames(svm.final.resamples.frame) <- c("pliegue", "C", "RMSE")
########### 4. BRNN #####################
set.seed(23)
paramGrid <- expand.grid(.neurons = c(1,2,3,4,5,10,20))
# Find the optimum combination of parameters
brnn.final <- caret::train(
output_train~., # We want to predict Temp_Comfort3B according to the predictors
data = train.pca.completo, # Inputs + Outputs
method = "brnn",
metric = "RMSE", # Metric to evaluate
tuneGrid = paramGrid, # Parameters for tunning
trControl = ctrl # Parameters of control
)
brnn.final.resamples.RMSE <- brnn.final$resample$RMSE
brnn.final.resamples.neurons <- factor(brnn.final$resample$neurons)
brnn.final.resamples.pliegue <- factor(brnn.final$resample$Resample)
brnn.final.resamples.frame <- data.frame(cbind(brnn.final.resamples.pliegue, brnn.final.resamples.neurons, brnn.final.resamples.RMSE))
colnames(brnn.final.resamples.frame) <- c("pliegue", "neurons", "RMSE")
##################################################################################
grouping <- c(rep("Gauss RBF", 50), rep("MLP", 50), rep("SVM", 50),  rep("Bayesian NN", 50))
grouping.factor <- factor(grouping)
outcome <- c(gauss.final.resamples.RMSE, mlp.final.resamples.RMSE, svm.final.resamples.RMSE, brnn.final.resamples.RMSE)
gauss.final.prediction <- predict(gauss.final, test.pca)
gauss.final.rmse <- RMSE(gauss.final.prediction, output_test, na.rm = FALSE)
gauss.final.r2 <- R2(gauss.final.prediction, output_test, formula = "corr", na.rm = FALSE)
mlp.final.prediction <- predict(mlp.final, test.pca)
mlp.final.rmse <- RMSE(mlp.final.prediction, output_test, na.rm = FALSE)
mlp.final.r2 <- R2(mlp.final.prediction, output_test, formula = "corr", na.rm = FALSE)
svm.final.prediction <- predict(svm.final, test.pca)
svm.final.rmse <- RMSE(svm.final.prediction, output_test, na.rm = FALSE)
svm.final.r2 <- R2(svm.final.prediction, output_test, formula = "corr", na.rm = FALSE)
brnn.final.prediction <- predict(brnn.final, test.pca)
brnn.final.rmse <- RMSE(brnn.final.prediction, output_test, na.rm = FALSE)
brnn.final.r2 <- R2(brnn.final.prediction, output_test, formula = "corr", na.rm = FALSE)
rf.final.prediction <- predict(rf.final, test.pca)
rf.final.rmse <- RMSE(rf.final.prediction, output_test, na.rm = FALSE)
rf.final.r2 <- R2(rf.final.prediction, output_test, formula = "corr", na.rm = FALSE)
results.rmse <- t(as.matrix(cbind(gauss.final.rmse, mlp.final.rmse, svm.final.rmse, brnn.final.rmse, rf.final.rmse)))
results.r2 <- t(as.matrix(cbind(gauss.final.r2, mlp.final.r2, svm.final.r2, brnn.final.r2, rf.final.r2)))
results.tune <- t(as.matrix(cbind(gauss.final$bestTune, mlp.final$bestTune, svm.final$bestTune, brnn.final$bestTune, rf.final$bestTune)))
results.cvrmse <- results.rmse/mean(output_test)*100
nombres <- c("gauss", "mlp", "svm", "brnn", "rf")
#barplot(results.rmse, main="RMSE using Test data (oC)", xlab="Techniques", col=mypalette, legend = c("Gauss", "MLP", "SVM", "BRNN"), beside=T, xlim = c(0, 10))
#barplot(results.r2, main="R-squared using Test data", xlab="Techniques", col=mypalette, legend = c("Gauss", "MLP", "SVM", "BRNN"), beside=T, xlim = c(0, 10))
# Save outputs:
#save("gauss.final", "mlp.final", "svm.final", "brnn.final", file = "results")
print(xtable(data.frame(nombres, results.tune ,results.rmse,results.cvrmse, results.r2 ), digits = c(5,5,3,5,5,5), caption=""), comment = F,include.rownames=FALSE)
print(names(inputs_test))
print(xtable(gauss.final$results, digits = c(3,3,5,5,5,5), caption="GAUSS"), comment = F,include.rownames=FALSE)
print(xtable(mlp.final$results, digits = c(3,3,5,5,5,5), caption="MLP"), comment = F,include.rownames=FALSE)
print(xtable(svm.final$results, digits = c(3,3,5,5,5,5), caption="SVM"), comment = F,include.rownames=FALSE)
print(xtable(brnn.final$results, digits = c(3,3,5,5,5,5), caption="BRNN"), comment = F,include.rownames=FALSE)
print(xtable(rf.final$results, digits = c(3,3,5,5,5,5), caption="RF"), comment = F,include.rownames=FALSE)
cat("\\clearpage")
}
f.TOTAL2 <- function(dfentrada, indexx, PCA = T){
df <- dfentrada
df2 <- df[indexx]
dfx <- df2
set.seed(23)
nTraining <- as.integer(nrow(dfx) * 0.75)
indices <- sample(1:nrow(dfx), nTraining)
training <- dfx[indices,]
test <- dfx[-indices,]
trainingData <- training
testData <- test
x <- nearZeroVar(trainingData, saveMetrics = F)
print("Se han borrado las siguientes por tener varianza cercana a cero")
print(rownames(nearZeroVar(trainingData, saveMetrics = T)[nearZeroVar(trainingData, saveMetrics = T)[,"nzv"] > 0, ] ))
trainingData <- trainingData[,-x]
testData <- testData[,-x]
# Standarization of both subsets
procValues <- preProcess(trainingData, method = c("center", "scale"))   #c("range")
trainNormalized <-  predict(procValues, trainingData)
testNormalized <-  predict(procValues, testData)
inputs_train <- subset(trainNormalized,select = -c(EaparcialSUM))
inputs_test <- subset(testNormalized,select = -c(EaparcialSUM))
output_train <- trainingData$EaparcialSUM
output_test <- testData$EaparcialSUM
# Applying PCA with the required number of components to get the 98% of confidence
set.seed(123)
transformador.pca <- preProcess(
inputs_train,
method = c("pca"),
thres = 0.98
)
if(PCA){
train.pca <- predict(transformador.pca, inputs_train)
test.pca <- predict(transformador.pca, inputs_test)
}
if(!PCA){
train.pca <- inputs_train
test.pca <- inputs_test
}
# Transformation of the training and test data into the PCA components
#
train.pca.completo <- cbind(train.pca, output_train)
test.pca.completo <- cbind(test.pca, output_test)
# Use t-times k-fold validation, with t = 5 and k = 10 (by default)
ctrl <- trainControl(method = "repeatedcv", repeats = 5, returnResamp = "all")
paramGrid <- expand.grid(.sigma = c(0.0005,0.01,0.05,0.08,0.1, 0.5, 1))
set.seed(23)
# Find the optimum combination of parameters
gauss.final <- caret::train(
output_train~., # We want to predict Temp_Comfort3B according to the predictors
data = train.pca.completo, # Inputs + Outputs
method = "gaussprRadial",
metric = "RMSE", # Metric to evaluate
tuneGrid = paramGrid, # Parameters for tunning
trControl = ctrl # Parameters of control
)
gauss.final.resamples.RMSE <- gauss.final$resample$RMSE
gauss.final.resamples.sigma <- factor(gauss.final$resample$sigma)
gauss.final.resamples.pliegue <- factor(gauss.final$resample$Resample)
gauss.final.resamples.frame <- data.frame(cbind(gauss.final.resamples.pliegue, gauss.final.resamples.sigma, gauss.final.resamples.RMSE))
colnames(gauss.final.resamples.frame) <- c("pliegue", "sigma", "RMSE")
# Random Forest
paramGrid <- expand.grid(.mtry = c(1:10))
set.seed(23)
# Find the optimum combination of parameters
rf.final <- caret::train(
output_train~., # We want to predict ENERGY_METER according to the predictors
data = train.pca.completo, # Inputs + Outputs
method = "rf",
metric = "RMSE", # Metric to evaluate
tuneGrid = paramGrid, # Parameters for tunning
trControl = ctrl, # Parameters of control
preProc = c("center", "scale")
)
rf.final.resamples.RMSE <- rf.final$resample$RMSE
rf.final.resamples.mtry <- factor(rf.final$resample$mtry)
rf.final.resamples.pliegue <- factor(rf.final$resample$Resample)
rf.final.resamples.frame <- data.frame(cbind(rf.final.resamples.pliegue, rf.final.resamples.mtry, rf.final.resamples.RMSE))
colnames(rf.final.resamples.frame) <- c("pliegue", "mtry", "RMSE")
#
########### 2. MLP #####################
# Find the optimum combination of parameters
paramGrid <- expand.grid(.size = c(34:40,50,60,65,70))
set.seed(23)
# Buscamos la mejor combinación de parámetros
mlp.final <- caret::train(
output_train~., # We want to predict Temp_Comfort3B according to the predictors
data = train.pca.completo, # Inputs + Outputs
method = "mlp",
metric = "RMSE",
tuneGrid = paramGrid,
trControl = ctrl,
learnFunc = "Rprop"
)
mlp.final.resamples.RMSE <- mlp.final$resample$RMSE
mlp.final.resamples.size <- factor(mlp.final$resample$size)
mlp.final.resamples.pliegue <- factor(mlp.final$resample$Resample)
mlp.final.resamples.frame <- data.frame(cbind(mlp.final.resamples.pliegue, mlp.final.resamples.size, mlp.final.resamples.RMSE))
colnames(mlp.final.resamples.frame) <- c("pliegue", "size", "RMSE")
########### 3. SVM #####################
# Grid with the parameters to assess
set.seed(23)
paramGrid <- expand.grid(.C = c(1:15,18,20,22))
# Find the optimum combination of parameters
svm.final <- caret::train(
output_train~., # We want to predict Temp_Comfort3B according to the predictors
data = train.pca.completo, # Inputs + Outputs
method = "svmRadialCost",
metric = "RMSE", # Metric to evaluate
tuneGrid = paramGrid, # Parameters for tunning
trControl = ctrl, # Parameters of control
preProc = c("center", "scale")
)
svm.final.resamples.RMSE <- svm.final$resample$RMSE
svm.final.resamples.C <- factor(svm.final$resample$C)
svm.final.resamples.pliegue <- factor(svm.final$resample$Resample)
svm.final.resamples.frame <- data.frame(cbind(svm.final.resamples.pliegue, svm.final.resamples.C, svm.final.resamples.RMSE))
colnames(svm.final.resamples.frame) <- c("pliegue", "C", "RMSE")
########### 4. BRNN #####################
set.seed(23)
paramGrid <- expand.grid(.neurons = c(1,2,3,4,5,10,20))
# Find the optimum combination of parameters
brnn.final <- caret::train(
output_train~., # We want to predict Temp_Comfort3B according to the predictors
data = train.pca.completo, # Inputs + Outputs
method = "brnn",
metric = "RMSE", # Metric to evaluate
tuneGrid = paramGrid, # Parameters for tunning
trControl = ctrl # Parameters of control
)
brnn.final.resamples.RMSE <- brnn.final$resample$RMSE
brnn.final.resamples.neurons <- factor(brnn.final$resample$neurons)
brnn.final.resamples.pliegue <- factor(brnn.final$resample$Resample)
brnn.final.resamples.frame <- data.frame(cbind(brnn.final.resamples.pliegue, brnn.final.resamples.neurons, brnn.final.resamples.RMSE))
colnames(brnn.final.resamples.frame) <- c("pliegue", "neurons", "RMSE")
##################################################################################
grouping <- c(rep("Gauss RBF", 50), rep("MLP", 50), rep("SVM", 50),  rep("Bayesian NN", 50))
grouping.factor <- factor(grouping)
outcome <- c(gauss.final.resamples.RMSE, mlp.final.resamples.RMSE, svm.final.resamples.RMSE, brnn.final.resamples.RMSE)
gauss.final.prediction <- predict(gauss.final, test.pca)
gauss.final.rmse <- RMSE(gauss.final.prediction, output_test, na.rm = FALSE)
gauss.final.r2 <- R2(gauss.final.prediction, output_test, formula = "corr", na.rm = FALSE)
mlp.final.prediction <- predict(mlp.final, test.pca)
mlp.final.rmse <- RMSE(mlp.final.prediction, output_test, na.rm = FALSE)
mlp.final.r2 <- R2(mlp.final.prediction, output_test, formula = "corr", na.rm = FALSE)
svm.final.prediction <- predict(svm.final, test.pca)
svm.final.rmse <- RMSE(svm.final.prediction, output_test, na.rm = FALSE)
svm.final.r2 <- R2(svm.final.prediction, output_test, formula = "corr", na.rm = FALSE)
brnn.final.prediction <- predict(brnn.final, test.pca)
brnn.final.rmse <- RMSE(brnn.final.prediction, output_test, na.rm = FALSE)
brnn.final.r2 <- R2(brnn.final.prediction, output_test, formula = "corr", na.rm = FALSE)
rf.final.prediction <- predict(rf.final, test.pca)
rf.final.rmse <- RMSE(rf.final.prediction, output_test, na.rm = FALSE)
rf.final.r2 <- R2(rf.final.prediction, output_test, formula = "corr", na.rm = FALSE)
results.rmse <- t(as.matrix(cbind(gauss.final.rmse, mlp.final.rmse, svm.final.rmse, brnn.final.rmse, rf.final.rmse)))
results.r2 <- t(as.matrix(cbind(gauss.final.r2, mlp.final.r2, svm.final.r2, brnn.final.r2, rf.final.r2)))
results.tune <- t(as.matrix(cbind(gauss.final$bestTune, mlp.final$bestTune, svm.final$bestTune, brnn.final$bestTune, rf.final$bestTune)))
results.cvrmse <- results.rmse/mean(output_test)*100
nombres <- c("gauss", "mlp", "svm", "brnn", "rf")
#barplot(results.rmse, main="RMSE using Test data (oC)", xlab="Techniques", col=mypalette, legend = c("Gauss", "MLP", "SVM", "BRNN"), beside=T, xlim = c(0, 10))
#barplot(results.r2, main="R-squared using Test data", xlab="Techniques", col=mypalette, legend = c("Gauss", "MLP", "SVM", "BRNN"), beside=T, xlim = c(0, 10))
# Save outputs:
#save("gauss.final", "mlp.final", "svm.final", "brnn.final", file = "results")
print(xtable(data.frame(nombres, results.tune ,results.rmse,results.cvrmse, results.r2 ), digits = c(5,5,3,5,5,5), caption=""), comment = F,include.rownames=FALSE)
print(names(inputs_test))
print(xtable(gauss.final$results, digits = c(3,3,5,5,5,5), caption="GAUSS"), comment = F,include.rownames=FALSE)
print(xtable(mlp.final$results, digits = c(3,3,5,5,5,5), caption="MLP"), comment = F,include.rownames=FALSE)
print(xtable(svm.final$results, digits = c(3,3,5,5,5,5), caption="SVM"), comment = F,include.rownames=FALSE)
print(xtable(brnn.final$results, digits = c(3,3,5,5,5,5), caption="BRNN"), comment = F,include.rownames=FALSE)
print(xtable(rf.final$results, digits = c(3,3,5,5,5,5), caption="RF"), comment = F,include.rownames=FALSE)
cat("\\clearpage")
}
# Chunk 6
library("xtable")
library(RColorBrewer)
library("caret")
library("plyr")
mypalette<-brewer.pal(6,"Spectral")
df3 <- df3
df3 <- na.omit(df3)
df <- df3
bp <- boxplot(df$EaparcialSUM)
indices <- which(df$EaparcialSUM %in% bp$out)
df <- df[-indices,]
#boxplot(df$EaparcialSUM)
dfentrada <- df
dfentrada$fecha <- as.Date(dfentrada$fecha, format = "%d/%m/%Y")
dfentrada <- dfentrada[dfentrada$fecha >= "2014-12-01",]
ind1 <- list(c(3,4,5,8,135,147))
ind1 <- list(c(3,4,5,8,135,138))
i=1
f.TOTAL(dfentrada,ind1[[i]],PCA=F)
libary("shiny")
libary("shiny")
runExample("01_hello", port=5050)
runExample("01_hello")
libray("shiny")
library("shiny")
runExample("01_hello",port = 80)
runExample("01_hello",port = 5050)
runExample("01_hello",port = 80)
library(caret)
library(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(3433)
IL <- grep("^IL", colnames(training), value=TRUE)
ILpredictors <- predictors[, IL]
dataframe <- data.frame(diagnosis, ILpredictors)
inTrain <- createDataPartition(dataframe$diagnosis, p=3/4)[[1]]
training <- df[inTrain, ]
testing <- df[-inTrain, ]
dataframe
str(dataframe)
setwd("~/Dropbox/COURSERA-PracticalMachinelearning/Peer_Assignment_AURORA")
load("my_model1.rda")
